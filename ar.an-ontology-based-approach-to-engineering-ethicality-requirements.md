---
id: 3rzwwbdp89l6j4ocd427xsw
title: An Ontology Based Approach to Engineering Ethicality Requirements
desc: ''
updated: 1748969452324
created: 1748969377194
---

- https://link.springer.com/article/10.1007/s10270-023-01115-3
- author: @renata-guizzardi
- topics: [[t.phil.ontology]] [[t.phil.ethics]]

## Abstract

In a world where Artificial Intelligence (AI) is pervasive, humans may feel threatened or at risk by giving up control to machines. In this context, ethicality becomes a major concern to prevent AI systems from being biased, making mistakes, or going rogue. Requirements Engineering (RE) is the research area that can exert a great impact in the development of ethical systems by design. However, proposing concepts, tools and techniques that support the incorporation of ethicality into the software development processes as explicit requirements remains a great challenge in the RE field. In this paper, we rely on Ontology-based Requirements Engineering (ObRE) as a method to elicit and analyze ethicality requirements (‘Ethicality requirements’ is adopted as a name for the class of requirements studied in this paper by analogy to other quality requirements studied in software engineering, such as usability, reliability, and portability, etc. The use of this term (as opposed to ‘ethical requirements’) highlights that they represent requirements for ethical systems, analogous to how ‘trustworthiness requirements’ represent requirements for trustworthy systems. To put simply: the predicates ‘ethical’ or ‘trustworthy’ are not meant to be predicated over the requirements themselves). ObRE applies ontological analysis to ontologically unpack terms and notions that are referred to in requirements elicitation. Moreover, this method instantiates the adopted ontology and uses it to guide the requirements analysis activity. In a previous paper, we presented a solution concerning two ethical principles, namely Beneficence and Non-maleficence. The present paper extends the previous work by targeting two other important ethicality principles, those of Explicability and Autonomy. For each of these new principles, we do ontological unpacking of the relevant concepts, and we present requirements elicitation and analysis guidelines, as well as examples in the context of a driverless car case. Furthermore, we validate our approach by analysing the requirements elicitation made for the driverless car case in contrast with a similar case, and by assessing our method’s coverage w.r.t European Union guidelines for Trustworthy AI.